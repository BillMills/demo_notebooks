{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2685c45",
   "metadata": {},
   "source": [
    "# Introduction to Argovis's API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ae6981",
   "metadata": {},
   "source": [
    "Argovis provides an API that indexes and distributes numerous oceanographic datasets with detailed query parameters, enabling you to search and download only and exactly data of interest. In this notebook, we'll tour some of the standard usage patterns enabled by Argovis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e01ce7",
   "metadata": {},
   "source": [
    "## Setup: Register an API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc372ab8",
   "metadata": {},
   "source": [
    "In order to allocate Argovis's limited computing resources fairly, users are encouraged to register and request a free API key. This works like a password that identifies your requests to Argovis. To do so:\n",
    "\n",
    " - Visit [https://argovis-keygen.colorado.edu/](https://argovis-keygen.colorado.edu/)\n",
    " - Fill out the form under _New Account Registration_\n",
    " - An API key will be emailed to you shortly.\n",
    " \n",
    "Treat this API key like a password - don't share it or leave it anywhere public. If you ever forget it or accidentally reveal it to a third party, see the same website above to change or deactivate your token.\n",
    "\n",
    "Put your API key in the quotes in the variable below before moving on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2882fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_ROOT='https://argovis-api.colorado.edu/'\n",
    "API_KEY=''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8abb70c",
   "metadata": {},
   "source": [
    "# Argovis data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aee7619",
   "metadata": {},
   "source": [
    "Argovis standard data structures divide measurements into _data_ and _metadata_ documents. Typically, a data document corresponds to measurements or gridded data associated with a discreet temporospatial column - a time, latitude and longitude. A single such document may contain measurements at multiple depths or altitudes, provided they share the same latitude, longitude, and time.\n",
    "\n",
    "Each of these data documents will refer to at least one corresponding metadata document that captures additional information about the measurement. Argovis divides information between data and metadata documents in order to minimize redundancy in the data you download: many data documents will point to the same metadata document, allowing you to only download that metadata once. Typically, these metadata groupings will refer to some meaningful characteristic of the data; Argo metadata documents correspond to physical floats, while CCHDO metadata documents correspond to cruises, for example.\n",
    "\n",
    "For more detail and specifications on the data and metadata documents for each collection, see [https://argovis.colorado.edu/docs/documentation/_build/html/data_management/schema.html](https://argovis.colorado.edu/docs/documentation/_build/html/data_management/schema.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40764e20",
   "metadata": {},
   "source": [
    "# The standard data routes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db8127e",
   "metadata": {},
   "source": [
    "## What datasets does Argovis index?\n",
    "\n",
    "Argovis supports several different data sets with the API and data structures described here. They and their corresponding routes are:\n",
    "\n",
    " - Argo profiling float data, `/argo`\n",
    " - CCHDO ship-based profile data, `/cchdo`\n",
    " - tropical cyclone data from HURDAT and JTWC, `/tc`\n",
    " - Global Drifter Program data, `/drifters`\n",
    " - several gridded products:\n",
    "   - Roemmich-Gilson total temperature and salinity, `/grids/rg09`\n",
    "   - ocean heat content, `/grids/kg21`\n",
    " - Argone Argo float position forecast model data, `/argone`\n",
    "   \n",
    "The examples that follow apply equally to all these routes; they all support similar query options and follow similar behavior patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c2c260",
   "metadata": {},
   "source": [
    "## Using Swagger and the `argovisHelpers` package to download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2680c0b2",
   "metadata": {},
   "source": [
    "In order to successfully explore Argovis data, there are two important tools to introduce in this section: Swagger, our API documentation engine, and `argovisHelpers`, our Python package of fuctions to help you access and interpret Argovis data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f60fff8",
   "metadata": {},
   "source": [
    "### Using Swagger docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbe5cd1",
   "metadata": {},
   "source": [
    "Argovis' API documentation is found at [https://argovis-api.colorado.edu/docs/](https://argovis-api.colorado.edu/docs/). These docs are split into several categories; what follows applies to all categories _not_ marked experimental; the experimental categories are under development and may change or be removed at any time.\n",
    "\n",
    "Categories have three typical routes:\n",
    " - The main _data route_, like `/argo`, or `/cchdo`. These routes provide the data documents for the dataset named in the route.\n",
    " - The _metadata route_, like `/argo/meta`. These routes provide the metadata documents referred to by data documents.\n",
    " - The _vocabulary route_, like `/argo/vocabulary`. These routes provide lists of possible options for search parameters used in the corresponding data and metadata routes.\n",
    " \n",
    "Click on any of the routes, like `/argo` - a list of possible query string parameters are presented, with a short explanation of what they mean.\n",
    "\n",
    "If you're familiar with REST APIs, this is enough information for you to construct a query string and issue a request in any programming environment that can facilitate an HTTP GET request. If you're working in Python, we provide a helper library, `argovisHelpers`, to manage these requests for you. Let's try it out by making our first request for Argo data, for profiles found within 100 km of a point in the South Atlantic in May 2011 (users of Python's `requests` module will notice a familiar pattern, providing the query string parameters listed in the Swagger docs and associated values as a dictionary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e339f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argovisHelpers import helpers as avh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e93feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "argoSearch = {\n",
    "    'startDate': '2011-05-01T00:00:00Z',\n",
    "    'endDate': '2011-06-01T00:00:00Z',\n",
    "    'center': '-22.5,0',\n",
    "    'radius': 100\n",
    "}\n",
    "\n",
    "argoProfiles = avh.query('argo', options=argoSearch, apikey=API_KEY, apiroot=API_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ae287",
   "metadata": {},
   "source": [
    "Let's have a look at what we get from the first profile returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412bf2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '4901283_003',\n",
       " 'geolocation': {'type': 'Point', 'coordinates': [-23.139, -0.154]},\n",
       " 'basin': 1,\n",
       " 'timestamp': '2011-05-02T08:26:28.000Z',\n",
       " 'date_updated_argovis': '2023-01-28T01:13:18.370Z',\n",
       " 'source': [{'source': ['argo_bgc'],\n",
       "   'url': 'ftp://ftp.ifremer.fr/ifremer/argo/dac/aoml/4901283/profiles/SD4901283_003.nc',\n",
       "   'date_updated': '2022-06-29T21:21:10.000Z'},\n",
       "  {'source': ['argo_core'],\n",
       "   'url': 'ftp://ftp.ifremer.fr/ifremer/argo/dac/aoml/4901283/profiles/D4901283_003.nc',\n",
       "   'date_updated': '2018-10-03T14:45:37.000Z'}],\n",
       " 'cycle_number': 3,\n",
       " 'geolocation_argoqc': 1,\n",
       " 'profile_direction': 'A',\n",
       " 'timestamp_argoqc': 1,\n",
       " 'vertical_sampling_scheme': 'Primary sampling: averaged []',\n",
       " 'data_info': [['doxy',\n",
       "   'doxy_argoqc',\n",
       "   'pressure',\n",
       "   'pressure_argoqc',\n",
       "   'salinity',\n",
       "   'salinity_argoqc',\n",
       "   'salinity_sfile',\n",
       "   'salinity_sfile_argoqc',\n",
       "   'temperature',\n",
       "   'temperature_argoqc',\n",
       "   'temperature_sfile',\n",
       "   'temperature_sfile_argoqc'],\n",
       "  ['units', 'data_keys_mode'],\n",
       "  [['micromole/kg', 'D'],\n",
       "   [None, None],\n",
       "   ['decibar', 'D'],\n",
       "   [None, None],\n",
       "   ['psu', 'D'],\n",
       "   [None, None],\n",
       "   ['psu', 'D'],\n",
       "   [None, None],\n",
       "   ['degree_Celsius', 'D'],\n",
       "   [None, None],\n",
       "   ['degree_Celsius', 'D'],\n",
       "   [None, None]]],\n",
       " 'metadata': ['4901283_m0']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argoProfiles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba72f87b",
   "metadata": {},
   "source": [
    "This is a data document for Argo, matching the specification at [https://argovis.colorado.edu/docs/documentation/_build/html/data_management/schema.html](https://argovis.colorado.edu/docs/documentation/_build/html/data_management/schema.html). It contains the `timestamp` and `geolocation` properties that place this profile geospatially, and other parameters that typically change from point to point.\n",
    "\n",
    "All data documents bear a `metadata` key, which is a pointer to the appropriate metadata document to find out more about this measurement. Let's fetch that document for this first profile by querying the `argo/meta` route for a doument with an `id` that matches this `metadata` pointer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89984fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': '4901283_m0',\n",
       "  'data_type': 'oceanicProfile',\n",
       "  'data_center': 'AO',\n",
       "  'instrument': 'profiling_float',\n",
       "  'pi_name': ['BRECK OWENS'],\n",
       "  'platform': '4901283',\n",
       "  'platform_type': 'SOLO_W',\n",
       "  'fleetmonitoring': 'https://fleetmonitoring.euro-argo.eu/float/4901283',\n",
       "  'oceanops': 'https://www.ocean-ops.org/board/wa/Platform?ref=4901283',\n",
       "  'positioning_system': 'GPS',\n",
       "  'wmo_inst_type': '851'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaOptions = {\n",
    "    'id': argoProfiles[0]['metadata'][0]\n",
    "}\n",
    "\n",
    "argoMeta = avh.query('argo/meta', options=metaOptions, apikey=API_KEY, apiroot=API_ROOT)\n",
    "argoMeta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b572ec5c",
   "metadata": {},
   "source": [
    "In addition to temporospatial searches, data and metadata routes typically support _category searches_, which are searches for documents that belong to certain categories. Which categories are available to search by changes logically from dataset to dataset; Argo floats can be searched by platform number, for example, while tropical cyclones can be searched by storm name. See the swagger docs for the full set of possibilities for each category; let's now use argo's platform category search to get all profiles collected by the same platform as the first profile above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e8f2e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "platformSearch = {\n",
    "    'platform': argoMeta[0]['platform']\n",
    "}\n",
    "\n",
    "platformProfiles = avh.query('argo', options=platformSearch, apikey=API_KEY, apiroot=API_ROOT)\n",
    "print(len(platformProfiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f78db8",
   "metadata": {},
   "source": [
    "At the time of writing, 125 profiles are found for this platform in this way.\n",
    "\n",
    "For all category searches, we may wish to know the full list of all possible values a category can take on; for this, there are the _vocabulary_ routes. Let's get a list of all possible Argo platforms we can search by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75b551c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['13857', '13858', '13859', '15819', '15820', '15851', '15852', '15853', '15854', '15855']\n"
     ]
    }
   ],
   "source": [
    "platformVocabSearch = {\n",
    "    'parameter': 'platform'\n",
    "}\n",
    "\n",
    "platforms = avh.query('argo/vocabulary', options=platformVocabSearch, apikey=API_KEY, apiroot=API_ROOT)\n",
    "print(platforms[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498dd372",
   "metadata": {},
   "source": [
    "Here we just print out the first 10 platform IDs found, but all 17 thousand or so are present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b742886",
   "metadata": {},
   "source": [
    "## Using the `data` query option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d690499",
   "metadata": {},
   "source": [
    "The astute reader may have noticed something about the data document shown above: there's no actual measurements included in it! By default, only the non-measurement data is returned, in order to minimize bandwidth consumed; in order to get back actual measurements and their QC flags, we must query and filter including the `data` parameter, the behavior of which we'll see in this section.\n",
    "\n",
    "### Basic data request\n",
    "\n",
    "Let's start by asking for one particular profile by ID, and ask for some temperature data to go with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c9bf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98, 100, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138, 140, 142, 144, 146, 148, 150, 152, 154, 156, 158, 160, 162, 164, 166, 168, 170, 172, 174, 176, 178, 180, 182, 184, 186, 188, 190, 192, 194, 196, 198, 200, 202, 204, 206, 208, 210, 212, 214, 216, 218, 220, 222, 224, 226, 228, 230, 232, 234, 236, 238, 240, 242, 244, 246, 248, 250, 252, 254, 256, 258, 260, 262, 264, 266, 268, 270, 272, 274, 276, 278, 280, 282, 284, 286, 288, 290, 292, 294, 296, 298, 300, 302, 304, 306, 308, 310, 312, 314, 316, 318, 320, 322, 324, 326, 328, 330, 332, 334, 336, 338, 340, 342, 344, 346, 348, 350, 352, 354, 356, 358, 360, 362, 364, 366, 368, 370, 372, 374, 376, 378, 380, 382, 384, 386, 388, 390, 392, 394, 396, 398, 400, 402, 404, 406, 408, 410, 412, 414, 416, 418, 420, 422, 424, 426, 428, 430, 432, 434, 436, 438, 440, 442, 444, 446, 448, 450, 452, 454, 456, 458, 460, 462, 464, 466, 468, 470, 472, 474, 476, 478, 480, 482, 484, 486, 488, 490, 492, 494, 496, 498, 500, 502, 504, 506, 508, 510, 512, 514, 516, 518, 520, 522, 524, 526, 528, 530, 532, 534, 536, 538, 540, 542, 544, 546, 548, 550, 552, 554, 556, 558, 560, 562, 564, 566, 568, 570, 572, 574, 576, 578, 580, 582, 584, 586, 588, 590, 592, 594, 596, 598, 600, 602, 604, 606, 608, 610, 612, 614, 616, 618, 620, 622, 624, 626, 628, 630, 632, 634, 636, 638, 640, 642, 644, 646, 648, 650, 652, 654, 656, 658, 660, 662, 664, 666, 668, 670, 672, 674, 676, 678, 680, 682, 684, 686, 688, 690, 692, 694, 696, 698, 700, 705, 710, 715, 720, 725, 730, 735, 740, 745, 750, 755, 760, 765, 770, 775, 780, 785, 790, 795, 800, 805, 810, 815, 820, 825, 830, 835, 840, 845, 850, 855, 860, 865, 870, 875, 880, 885, 890, 895, 900, 905, 910, 915, 920, 925, 930, 935, 940, 945, 950, 955, 960, 965, 970, 975, 980, 985, 990, 995, 1000, 1005, 1010, 1015, 1020, 1025, 1030, 1035, 1040, 1045, 1050, 1055, 1060, 1065], [28.669001, 28.667999, 28.722, 28.816, 28.823, 28.826, 28.830999, 28.783001, 28.775999, 28.740999, 28.694, 28.551001, 28.497, 28.489, 28.414, 28.191999, 28.087999, 28.044001, 27.836, 27.715, 27.655001, 27.41, 27.125999, 26.805, 26.500999, 26.311001, 26.075001, 25.448, 25.120001, 24.632999, 23.709, 22.400999, 21.893, 21.523001, 21.122, 20.861, 20.657, 20.104, 19.707001, 19.681, 19.573999, 19.396999, 19.181, 18.747, 18.438999, 18.240999, 18.045, 17.882, 17.783001, 17.664, 17.563, 17.474001, 17.370001, 17.250999, 17.006001, 16.861, 16.638, 16.465, 16.337999, 16.142, 15.902, 15.721, 15.585, 15.415, 15.28, 15.214, 15.158, 15.084, 15.039, 14.989, 14.91, 14.792, 14.726, 14.698, 14.681, 14.654, 14.618, 14.589, 14.546, 14.459, 14.389, 14.329, 14.219, 14.137, 14.074, 14.039, 14, 13.966, 13.928, 13.851, 13.83, 13.826, 13.823, 13.819, 13.812, 13.808, 13.809, 13.81, 13.808, 13.769, 13.753, 13.736, 13.721, 13.694, 13.657, 13.625, 13.608, 13.584, 13.547, 13.524, 13.508, 13.485, 13.457, 13.418, 13.364, 13.291, 13.23, 13.148, 12.999, 12.903, 12.843, 12.819, 12.807, 12.767, 12.714, 12.692, 12.691, 12.689, 12.688, 12.682, 12.668, 12.639, 12.573, 12.476, 12.336, 12.064, 11.854, 11.74, 11.69, 11.638, 11.583, 11.478, 11.419, 11.361, 11.282, 11.241, 11.178, 11.107, 11.059, 11.055, 11.045, 11.034, 11.015, 11, 10.985, 10.975, 10.956, 10.936, 10.864, 10.482, 10.09, 9.975, 9.848, 9.83, 9.829, 9.807, 9.784, 9.768, 9.749, 9.725, 9.672, 9.634, 9.629, 9.617, 9.587, 9.535, 9.465, 9.442, 9.411, 9.385, 9.36, 9.33, 9.278, 9.21, 9.138, 9.091, 9.051, 9, 8.964, 8.918, 8.88, 8.82, 8.732, 8.658, 8.607, 8.576, 8.558, 8.554, 8.549, 8.541, 8.535, 8.527, 8.514, 8.49, 8.476, 8.462, 8.432, 8.372, 8.297, 8.198, 8.156, 8.111, 8.024, 7.953, 7.884, 7.775, 7.755, 7.746, 7.734, 7.692, 7.665, 7.635, 7.606, 7.602, 7.598, 7.593, 7.586, 7.581, 7.577, 7.572, 7.563, 7.551, 7.539, 7.521, 7.516, 7.507, 7.495, 7.479, 7.433, 7.396, 7.368, 7.344, 7.299, 7.26, 7.227, 7.227, 7.227, 7.195, 7.138, 7.109, 7.097, 7.088, 7.072, 7.05, 7.032, 7.012, 6.994, 6.984, 6.982, 6.981, 6.979, 6.978, 6.975, 6.971, 6.955, 6.896, 6.884, 6.878, 6.853, 6.833, 6.809, 6.794, 6.78, 6.772, 6.768, 6.765, 6.763, 6.758, 6.756, 6.75, 6.739, 6.713, 6.685, 6.62, 6.577, 6.555, 6.545, 6.532, 6.518, 6.506, 6.491, 6.473, 6.459, 6.449, 6.442, 6.429, 6.401, 6.37, 6.351, 6.344, 6.34, 6.338, 6.335, 6.331, 6.319, 6.314, 6.311, 6.305, 6.291, 6.281, 6.274, 6.266, 6.257, 6.25, 6.247, 6.244, 6.241, 6.236, 6.22, 6.204, 6.187, 6.181, 6.176, 6.174, 6.17, 6.167, 6.165, 6.163, 6.147, 6.13, 6.127, 6.126, 6.123, 6.116, 6.11, 6.094, 6.085, 6.052, 6.024, 5.986, 5.968, 5.958, 5.939, 5.923, 5.912, 5.888, 5.858, 5.834, 5.822, 5.802, 5.788, 5.767, 5.619, 5.357, 5.272, 5.173, 5.101, 5.089, 5.084, 5.064, 5.013, 4.994, 4.986, 4.983, 4.978, 4.962, 4.972, 4.98, 4.954, 4.934, 4.889, 4.853, 4.817, 4.767, 4.73, 4.72, 4.72, 4.719, 4.713, 4.706, 4.702, 4.699, 4.679, 4.653, 4.647, 4.639, 4.63, 4.626, 4.619, 4.616, 4.61, 4.601, 4.598, 4.592, 4.582, 4.574, 4.548, 4.517, 4.492, 4.471, 4.452, 4.444, 4.489, 4.51, 4.531, 4.509, 4.483, 4.488, 4.498, 4.51, 4.522, 4.534, 4.53, 4.522, 4.513, 4.51, 4.514, 4.516, 4.517, 4.516, 4.514, 4.511, 4.51]]\n"
     ]
    }
   ],
   "source": [
    "dataQuery = {\n",
    "    'id': '4901283_003',\n",
    "    'data': 'temperature'\n",
    "}\n",
    "\n",
    "profile = avh.query('argo', options=dataQuery, apikey=API_KEY, apiroot=API_ROOT)\n",
    "print(profile[0]['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4150f98a",
   "metadata": {},
   "source": [
    "The `data` key contains a list of lists of measurements. To interpret them, we use the `data_info` key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15ce9b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['pressure', 'temperature'], ['units', 'data_keys_mode'], [['decibar', 'D'], ['degree_Celsius', 'D']]]\n"
     ]
    }
   ],
   "source": [
    "print(profile[0]['data_info'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8940a0",
   "metadata": {},
   "source": [
    "`data_info` is always a list that contains exactly three items:\n",
    "\n",
    " - `data_info[0]` is the list of measurements returned in our `data` object, in the same order as `data`. So in the example above, `data[0]` are pressure measurements, while `data[1]` are temperature measurements. Note we got back pressures even though we only asked for temperatures; pressures are always provided where available as they are needed to meaningfully interpret all other data variables.\n",
    " - `data_info[1]` is a list of per-measurement variables. In the example above, pressure and temperature both have a `units` and a `data_keys_mode` associated with them.\n",
    " - `data_info[2]` is a rank 2 matrix with rows labeled by `data_info[0]` and columns by `data_info[1]`. So for the example above, this matrix indicates pressure has units 'decibar', and temperature has `data_keys_mode` 'D'.\n",
    " \n",
    "With this information, we now understand how to interpret the `data` key above: the first list is a list of pressures measured in decibar, and the second list are corresponding temperature measurements measured in degrees C. Note that the ith elements in the data lists all correspond to the same level - in other words, `data[0][i],  data[1][i], data[2][1], ....` are all measurements corresponding to the ith level of this object.\n",
    " \n",
    "> **Data and metadata precedence**: sometimes, you might see a given key on *both* a data document and its corresponding metadata document; when this happens, the value on the data document always takes precedence. `data_info` is a common example of this, which we'll see again below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af8104",
   "metadata": {},
   "source": [
    "### Data inflation\n",
    "\n",
    "If you find this format difficult to consume, another option is to use the `data_inflate` function from the argovis helpers package. This function will turn your data array into a list of dictionaries, one dictionary per level, with keys corresponding to the data values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adeb43a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pressure': 2, 'temperature': 28.669001},\n",
       " {'pressure': 4, 'temperature': 28.667999},\n",
       " {'pressure': 6, 'temperature': 28.722},\n",
       " {'pressure': 8, 'temperature': 28.816},\n",
       " {'pressure': 10, 'temperature': 28.823},\n",
       " {'pressure': 12, 'temperature': 28.826},\n",
       " {'pressure': 14, 'temperature': 28.830999},\n",
       " {'pressure': 16, 'temperature': 28.783001},\n",
       " {'pressure': 18, 'temperature': 28.775999},\n",
       " {'pressure': 20, 'temperature': 28.740999}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inflated_data = avh.data_inflate(profile[0])\n",
    "inflated_data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4377bba0",
   "metadata": {},
   "source": [
    "This format is inefficient to download, but easy to read and work with. Long-time users of previous versions of Argovis may recognize this as similar to the legacy format of some of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaed171",
   "metadata": {},
   "source": [
    "### Getting absolutely everything\n",
    "\n",
    "What we've seen above allows us to be very targeted in the data we download; rather than being forced to spend time and bandwidth downloading data we aren't interested in, we can focus on just what we need. On the other hand, somtimes we really do want everything, and for that there's `data=all`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35f04b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doxy': None,\n",
       "  'doxy_argoqc': 4,\n",
       "  'pressure': 2,\n",
       "  'pressure_argoqc': 1,\n",
       "  'salinity': 35.574966,\n",
       "  'salinity_argoqc': 1,\n",
       "  'salinity_sfile': 35.574966,\n",
       "  'salinity_sfile_argoqc': 1,\n",
       "  'temperature': 28.669001,\n",
       "  'temperature_argoqc': 1,\n",
       "  'temperature_sfile': 28.669001,\n",
       "  'temperature_sfile_argoqc': 1},\n",
       " {'doxy': None,\n",
       "  'doxy_argoqc': 4,\n",
       "  'pressure': 4,\n",
       "  'pressure_argoqc': 1,\n",
       "  'salinity': 35.573761,\n",
       "  'salinity_argoqc': 1,\n",
       "  'salinity_sfile': 35.573761,\n",
       "  'salinity_sfile_argoqc': 1,\n",
       "  'temperature': 28.667999,\n",
       "  'temperature_argoqc': 1,\n",
       "  'temperature_sfile': 28.667999,\n",
       "  'temperature_sfile_argoqc': 1},\n",
       " {'doxy': None,\n",
       "  'doxy_argoqc': 4,\n",
       "  'pressure': 6,\n",
       "  'pressure_argoqc': 1,\n",
       "  'salinity': 35.626602,\n",
       "  'salinity_argoqc': 1,\n",
       "  'salinity_sfile': 35.626602,\n",
       "  'salinity_sfile_argoqc': 1,\n",
       "  'temperature': 28.722,\n",
       "  'temperature_argoqc': 1,\n",
       "  'temperature_sfile': 28.722,\n",
       "  'temperature_sfile_argoqc': 1},\n",
       " {'doxy': None,\n",
       "  'doxy_argoqc': 4,\n",
       "  'pressure': 8,\n",
       "  'pressure_argoqc': 1,\n",
       "  'salinity': 35.752064,\n",
       "  'salinity_argoqc': 1,\n",
       "  'salinity_sfile': 35.752064,\n",
       "  'salinity_sfile_argoqc': 1,\n",
       "  'temperature': 28.816,\n",
       "  'temperature_argoqc': 1,\n",
       "  'temperature_sfile': 28.816,\n",
       "  'temperature_sfile_argoqc': 1},\n",
       " {'doxy': None,\n",
       "  'doxy_argoqc': 4,\n",
       "  'pressure': 10,\n",
       "  'pressure_argoqc': 1,\n",
       "  'salinity': 35.763969,\n",
       "  'salinity_argoqc': 1,\n",
       "  'salinity_sfile': 35.763969,\n",
       "  'salinity_sfile_argoqc': 1,\n",
       "  'temperature': 28.823,\n",
       "  'temperature_argoqc': 1,\n",
       "  'temperature_sfile': 28.823,\n",
       "  'temperature_sfile_argoqc': 1},\n",
       " {'doxy': None,\n",
       "  'doxy_argoqc': 4,\n",
       "  'pressure': 12,\n",
       "  'pressure_argoqc': 1,\n",
       "  'salinity': 35.769985,\n",
       "  'salinity_argoqc': 1,\n",
       "  'salinity_sfile': 35.769985,\n",
       "  'salinity_sfile_argoqc': 1,\n",
       "  'temperature': 28.826,\n",
       "  'temperature_argoqc': 1,\n",
       "  'temperature_sfile': 28.826,\n",
       "  'temperature_sfile_argoqc': 1},\n",
       " {'doxy': None,\n",
       "  'doxy_argoqc': 4,\n",
       "  'pressure': 14,\n",
       "  'pressure_argoqc': 1,\n",
       "  'salinity': 35.777859,\n",
       "  'salinity_argoqc': 1,\n",
       "  'salinity_sfile': 35.777859,\n",
       "  'salinity_sfile_argoqc': 1,\n",
       "  'temperature': 28.830999,\n",
       "  'temperature_argoqc': 1,\n",
       "  'temperature_sfile': 28.830999,\n",
       "  'temperature_sfile_argoqc': 1},\n",
       " {'doxy': None,\n",
       "  'doxy_argoqc': 4,\n",
       "  'pressure': 16,\n",
       "  'pressure_argoqc': 1,\n",
       "  'salinity': 35.805309,\n",
       "  'salinity_argoqc': 1,\n",
       "  'salinity_sfile': 35.805309,\n",
       "  'salinity_sfile_argoqc': 1,\n",
       "  'temperature': 28.783001,\n",
       "  'temperature_argoqc': 1,\n",
       "  'temperature_sfile': 28.783001,\n",
       "  'temperature_sfile_argoqc': 1},\n",
       " {'doxy': None,\n",
       "  'doxy_argoqc': 4,\n",
       "  'pressure': 18,\n",
       "  'pressure_argoqc': 1,\n",
       "  'salinity': 35.822716,\n",
       "  'salinity_argoqc': 1,\n",
       "  'salinity_sfile': 35.822716,\n",
       "  'salinity_sfile_argoqc': 1,\n",
       "  'temperature': 28.775999,\n",
       "  'temperature_argoqc': 1,\n",
       "  'temperature_sfile': 28.775999,\n",
       "  'temperature_sfile_argoqc': 1},\n",
       " {'doxy': None,\n",
       "  'doxy_argoqc': 4,\n",
       "  'pressure': 20,\n",
       "  'pressure_argoqc': 1,\n",
       "  'salinity': 35.869289,\n",
       "  'salinity_argoqc': 1,\n",
       "  'salinity_sfile': 35.869289,\n",
       "  'salinity_sfile_argoqc': 1,\n",
       "  'temperature': 28.740999,\n",
       "  'temperature_argoqc': 1,\n",
       "  'temperature_sfile': 28.740999,\n",
       "  'temperature_sfile_argoqc': 1}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataQuery = {\n",
    "    'id': '4901283_003',\n",
    "    'data': 'all'\n",
    "}\n",
    "\n",
    "profile = avh.query('argo', options=dataQuery, apikey=API_KEY, apiroot=API_ROOT)\n",
    "avh.data_inflate(profile[0])[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53be957f",
   "metadata": {},
   "source": [
    "### Filtering behavior of data requests\n",
    "\n",
    "Note that adding a specific data filter is a _firm requirement_ that all returned profiles have some meaningful data for _all_ variables listed. Try demanding chlorophyl-a in addition to temperature for our current profile of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "486f9b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "dataQuery = {\n",
    "    'id': '4901283_003',\n",
    "    'data': 'temperature,chla'\n",
    "}\n",
    "\n",
    "profile = avh.query('argo', options=dataQuery, apikey=API_KEY, apiroot=API_ROOT)\n",
    "print(profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d442245d",
   "metadata": {},
   "source": [
    "We get nothing in our array of profiles; even though we asked for profile id '4901283_003' and we know it exists, `data=temperature,chla` filters our query down to _only_ profiles that have both temperature and chla reported; since the profile requested doesn't have any chla measurements, it is dropped from the returns in this case. This is useful if you only want to download profiles that definitely have data of interest; for example, try the same thing on our regional search from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bd6740e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "argoSearch = {\n",
    "    'startDate': '2011-05-01T00:00:00Z',\n",
    "    'endDate': '2011-06-01T00:00:00Z',\n",
    "    'center': '-22.5,0',\n",
    "    'radius': 100,\n",
    "    'data': 'temperature,chla'\n",
    "}\n",
    "\n",
    "argoProfiles = avh.query('argo', options=argoSearch, apikey=API_KEY, apiroot=API_ROOT)\n",
    "print(len(argoProfiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2d8694",
   "metadata": {},
   "source": [
    "Evidently Argo made no chlorophyl-a measurements in May 2011 within 100 km of our point of interest - a fact which we found using the data api without having to download or reduce any data at all. One final point on data filtering in this manner: it's not enough for a profile to nominally have a variable defined for it; it must have at least one non-null value reported for that variable somewhere in the search results. For example, when we did `data=all` for our profile of interest above, we saw dissolved oxygen, `doxy`, was defined for it. But:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9abe692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "dataQuery = {\n",
    "    'id': '4901283_003',\n",
    "    'data': 'doxy'\n",
    "}\n",
    "\n",
    "profile = avh.query('argo', options=dataQuery, apikey=API_KEY, apiroot=API_ROOT)\n",
    "print(profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd88e27",
   "metadata": {},
   "source": [
    "Again our search is filtered down to nothing, since every level in that profile reported `None` for `doxy`.\n",
    "\n",
    "### Search negation\n",
    "\n",
    "Let's find some profiles that do actually have dissolved oxygen in them, this time with a slightly different geography search: let's look for everything in August 2017 within a polygon region, defined as a list of `[longitude, latitude]` points: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d7f3b1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'avh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m dataQuery \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstartDate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2017-08-01T00:00:00Z\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mendDate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2017-09-01T00:00:00Z\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolygon\u001b[39m\u001b[38;5;124m'\u001b[39m: [[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m150\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m30\u001b[39m],[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m155\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m30\u001b[39m],[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m155\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m35\u001b[39m],[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m150\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m35\u001b[39m],[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m150\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m30\u001b[39m]],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoxy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m }\n\u001b[0;32m----> 8\u001b[0m profiles \u001b[38;5;241m=\u001b[39m \u001b[43mavh\u001b[49m\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margo\u001b[39m\u001b[38;5;124m'\u001b[39m, options\u001b[38;5;241m=\u001b[39mdataQuery, apikey\u001b[38;5;241m=\u001b[39mAPI_KEY, apiroot\u001b[38;5;241m=\u001b[39mAPI_ROOT)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mset\u001b[39m(profiles))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'avh' is not defined"
     ]
    }
   ],
   "source": [
    "dataQuery = {\n",
    "    'startDate': '2017-08-01T00:00:00Z',\n",
    "    'endDate': '2017-09-01T00:00:00Z',\n",
    "    'polygon': [[-150,-30],[-155,-30],[-155,-35],[-150,-35],[-150,-30]],\n",
    "    'data': 'doxy'\n",
    "}\n",
    "\n",
    "profiles = avh.query('argo', options=dataQuery, apikey=API_KEY, apiroot=API_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587e8029",
   "metadata": {},
   "source": [
    "We find one profile with meaningful dissolved oxygen data in the region of interest.\n",
    "\n",
    "The `data` key also accepts _tilde negation_, meaning 'filter for profiles that _don't_ contain this data', for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97200c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "dataQuery = {\n",
    "    'startDate': '2017-08-01T00:00:00Z',\n",
    "    'endDate': '2017-09-01T00:00:00Z',\n",
    "    'polygon': [[-150,-30],[-155,-30],[-155,-35],[-150,-35],[-150,-30]],\n",
    "    'data': 'temperature,~doxy'\n",
    "}\n",
    "\n",
    "profiles = avh.query('argo', options=dataQuery, apikey=API_KEY, apiroot=API_ROOT)\n",
    "print(len(profiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e1951",
   "metadata": {},
   "source": [
    "We get a collection of profiles that appear in the region of interest, and have temperature but _not_ dissolved oxygen. In this way, we can split up our downloads into groups of related and interesting profiles without re-downloading the same profiles over and over."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d103f04",
   "metadata": {},
   "source": [
    "### Minimal data responses\n",
    "\n",
    "Sometimes, we might want to use the `data` filter as we've seen to confine our attention to only profiles that have data of interest, but we're only interested in general or metadata about those measurements, and don't want to download the actual measurements; for this, we can add the `except-data-values` token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b20a2e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': '5905107_001', 'geolocation': {'type': 'Point', 'coordinates': [-154.974, -32.415]}, 'basin': 2, 'timestamp': '2017-08-11T11:57:19.001Z', 'date_updated_argovis': '2023-01-27T08:37:16.397Z', 'source': [{'source': ['argo_bgc'], 'url': 'ftp://ftp.ifremer.fr/ifremer/argo/dac/aoml/5905107/profiles/SD5905107_001.nc', 'date_updated': '2022-07-09T07:14:33.000Z'}, {'source': ['argo_core'], 'url': 'ftp://ftp.ifremer.fr/ifremer/argo/dac/aoml/5905107/profiles/D5905107_001.nc', 'date_updated': '2019-06-24T15:29:23.000Z'}], 'cycle_number': 1, 'geolocation_argoqc': 1, 'profile_direction': 'A', 'timestamp_argoqc': 1, 'vertical_sampling_scheme': 'Primary sampling: mixed [deeper than nominal 985dbar: discrete; nominal 985dbar to surface: 2dbar-bin averaged]', 'data_info': [['doxy', 'pressure'], ['units', 'data_keys_mode'], [['micromole/kg', 'D'], ['decibar', 'D']]], 'metadata': ['5905107_m0']}]\n"
     ]
    }
   ],
   "source": [
    "dataQuery = {\n",
    "    'startDate': '2017-08-01T00:00:00Z',\n",
    "    'endDate': '2017-09-01T00:00:00Z',\n",
    "    'polygon': [[-150,-30],[-155,-30],[-155,-35],[-150,-35],[-150,-30]],\n",
    "    'data': 'doxy,except-data-values'\n",
    "}\n",
    "\n",
    "profiles = avh.query('argo', options=dataQuery, apikey=API_KEY, apiroot=API_ROOT)\n",
    "print(profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2ace64",
   "metadata": {},
   "source": [
    "Note that specifying only `'data': 'except-data-values'` is the same as just leaving the `data` query key off completely; the purpose of this option is to allow you to filter by data, but then only get back the lightweight non-measurement values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decff522",
   "metadata": {},
   "source": [
    "If we want an even more minimal response, we can use the `compression=minimal` option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14951d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['5905107_001', -154.974, -32.415, '2017-08-11T11:57:19.001Z', ['argo_bgc', 'argo_core']]]\n"
     ]
    }
   ],
   "source": [
    "dataQuery = {\n",
    "    'startDate': '2017-08-01T00:00:00Z',\n",
    "    'endDate': '2017-09-01T00:00:00Z',\n",
    "    'polygon': [[-150,-30],[-155,-30],[-155,-35],[-150,-35],[-150,-30]],\n",
    "    'data': 'doxy',\n",
    "    'compression': 'minimal'\n",
    "}\n",
    "\n",
    "profiles = avh.query('argo', options=dataQuery, apikey=API_KEY, apiroot=API_ROOT)\n",
    "print(profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35fed3d",
   "metadata": {},
   "source": [
    "With `compression: minimal`, for each data document we get only a minimal amount of information describing it; each data product has a slightly different minimal representation tailored to suit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argovis_demos",
   "language": "python",
   "name": "argovis_demos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
